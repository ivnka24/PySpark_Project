{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Salinan dari Untitled11.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMLGljfSh8kpG6COnS3sn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivnka24/PySpark_Project/blob/main/PySpark_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuk0WS5TLuWU",
        "outputId": "84285c7d-069b-4d82-c400-f09339674ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.13\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Python dan PySpark SQL"
      ],
      "metadata": {
        "id": "2ynK13Gw2fzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "id": "Hj-vpW9tMUwf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://dlcdn.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz"
      ],
      "metadata": {
        "id": "sm0BkED2Medu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "A1Ew33LgMnCv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "LSJkW5BvMovw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "fDJjEFa4Mqwx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        " .master(\"local\")\\\n",
        " .appName(\"Colab\")\\\n",
        " .config('spark.ui.port', '4050')\\\n",
        " .getOrCreate()"
      ],
      "metadata": {
        "id": "WbXhzmvxMzwe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load File Dataset"
      ],
      "metadata": {
        "id": "OyKxzea22pKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --continue https://raw.githubusercontent.com/dhanifudin/pyspark-demo/main/sample_books.json -O /tmp/sample_books.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2H_ayEHAM3pe",
        "outputId": "63422143-7176-4d87-dda4-7342a29ea4d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-06 02:29:56--  https://raw.githubusercontent.com/dhanifudin/pyspark-demo/main/sample_books.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1565 (1.5K) [text/plain]\n",
            "Saving to: ‘/tmp/sample_books.json’\n",
            "\n",
            "\r/tmp/sample_books.j   0%[                    ]       0  --.-KB/s               \r/tmp/sample_books.j 100%[===================>]   1.53K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-06-06 02:29:57 (17.6 MB/s) - ‘/tmp/sample_books.json’ saved [1565/1565]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.json(\"/tmp/sample_books.json\")"
      ],
      "metadata": {
        "id": "H_4chimOOm9v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ3O6I4VOrKd",
        "outputId": "e8dfb987-1de2-4f04-9537-2f4c139ae20e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- author: string (nullable = true)\n",
            " |-- edition: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year_written: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Praktikum"
      ],
      "metadata": {
        "id": "CMg0JNfo2z3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(4,False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tScyWZS1Ot6g",
        "outputId": "6157c257-7249-435c-ab80-9807e843d634"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+--------------+-----+----------------+------------+\n",
            "|author         |edition       |price|title           |year_written|\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "|Austen, Jane   |Penguin       |18.2 |Northanger Abbey|1814        |\n",
            "|Tolstoy, Leo   |Penguin       |12.7 |War and Peace   |1865        |\n",
            "|Tolstoy, Leo   |Penguin       |13.5 |Anna Karenina   |1875        |\n",
            "|Woolf, Virginia|Harcourt Brace|25.0 |Mrs. Dalloway   |1925        |\n",
            "+---------------+--------------+-----+----------------+------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aga9wdJyOxMt",
        "outputId": "f2ffed99-7905-4d1b-be69-95147e179d38"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"title\", \"price\", \"year_written\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3K_gbTLO0Fn",
        "outputId": "ac568d1d-4f4e-4aa8-830f-6fcb57fa91fb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+------------+\n",
            "|           title|price|year_written|\n",
            "+----------------+-----+------------+\n",
            "|Northanger Abbey| 18.2|        1814|\n",
            "|   War and Peace| 12.7|        1865|\n",
            "|   Anna Karenina| 13.5|        1875|\n",
            "|   Mrs. Dalloway| 25.0|        1925|\n",
            "|       The Hours|12.35|        1999|\n",
            "+----------------+-----+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered1 = df.filter(\"year_written > 1950 AND price > 10 AND title IS NOT NULL\")\n",
        "df_filtered1.select(\"title\", \"price\", \"year_written\").show(50, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lAUTuVwO2cv",
        "outputId": "fae3a319-35a4-44ae-fdeb-0879924a47d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+-----+------------+\n",
            "|title                        |price|year_written|\n",
            "+-----------------------------+-----+------------+\n",
            "|The Hours                    |12.35|1999        |\n",
            "|Harry Potter                 |19.95|2000        |\n",
            "|One Hundred Years of Solitude|14.0 |1967        |\n",
            "+-----------------------------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import max\n",
        "df_filtered = df.select(\"year_written\",\"title\",\"price\")\n",
        "\n",
        "# Find the costliest book\n",
        "\n",
        "maxValue = df_filtered.agg(max(\"price\")).collect()[0][0]\n",
        "print(\"maxValue: \",maxValue)\n",
        "df_filtered.select(\"title\",\"price\").filter(df.price == maxValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kzzbi0tPHQf",
        "outputId": "9e4392d4-9d08-486f-c213-606a2354977d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxValue:  29.0\n",
            "+-------------------+-----+\n",
            "|title              |price|\n",
            "+-------------------+-----+\n",
            "|A Room of One's Own|29.0 |\n",
            "+-------------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tugas Praktikum"
      ],
      "metadata": {
        "id": "ovaRMqlm2Y0w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1.tampilkan data buku paling murah\n",
        "from pyspark.sql.functions import min\n",
        "# Find the costliest book\n",
        "minValue = df_filtered.agg(min(\"price\")).collect()[0][0]\n",
        "print(\"minValue: \",minValue)\n",
        "\n",
        "df_filtered.select(\"title\",\"price\").filter(df.price == minValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgvNsJVwQcbt",
        "outputId": "a714924f-4f06-47ed-9990-2ecd0c211f80"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minValue:  5.75\n",
            "+-----------+-----+\n",
            "|title      |price|\n",
            "+-----------+-----+\n",
            "|Bleak House|5.75 |\n",
            "+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2.Tampilkan jumlah terbit buku dikategorikan setiap tahun ditulis!\n",
        "from pyspark.sql import functions as s \n",
        "df.groupby(\"year_written\").agg(s.count(\"year_written\").alias(\"jumlah\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxeNmq6kRfw3",
        "outputId": "bd8187ff-46d9-4da9-e871-739fbfcc417d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|year_written|jumlah|\n",
            "+------------+------+\n",
            "|        1967|     1|\n",
            "|        1937|     1|\n",
            "|        1862|     1|\n",
            "|        1999|     1|\n",
            "|        1875|     1|\n",
            "|        1925|     1|\n",
            "|        1814|     1|\n",
            "|        1865|     2|\n",
            "|        1922|     1|\n",
            "|        2000|     1|\n",
            "|        1870|     1|\n",
            "|        1603|     1|\n",
            "+------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #3.Tampilkan data buku termahal tiap tahun penulisannya!\n",
        "from pyspark.sql.functions import max # Find the costliest book\n",
        "maxValue = df_filtered.agg(max(\"price\")).collect()[0][0]\n",
        "print(\"maxValue: \",maxValue)\n",
        "\n",
        "df_filtered.select(\"year_written\",\"price\").filter(df.price == maxValue).show(20, False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuuffZK2fWSj",
        "outputId": "027e6e34-b350-431a-9708-3a57044febed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maxValue:  29.0\n",
            "+------------+-----+\n",
            "|year_written|price|\n",
            "+------------+-----+\n",
            "|1922        |29.0 |\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #4.Tampilkan data buku termurah tiap tahun penulisannya!\n",
        "from pyspark.sql.functions import min # Find the costliest book\n",
        "minValue = df_filtered.agg(min(\"price\")).collect()[0][0]\n",
        "print(\"minValue: \",minValue)\n",
        "\n",
        "df_filtered.select(\"year_written\",\"price\").filter(df.price == minValue).show(20, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlX3f4URhUy0",
        "outputId": "973f8170-0e5b-434f-b870-dc8197eaab55"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minValue:  5.75\n",
            "+------------+-----+\n",
            "|year_written|price|\n",
            "+------------+-----+\n",
            "|1870        |5.75 |\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}